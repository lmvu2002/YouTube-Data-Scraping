{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig, RobertaForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import json\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model_eng = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(MODEL)\n",
    "text = \"Hi!\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model_eng(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[2 1 0]\n",
      "1) positive 0.7172\n",
      "2) neutral 0.2652\n",
      "3) negative 0.0176\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(scores)\n",
    "print(ranking)\n",
    "ranking = ranking[::-1]\n",
    "print(ranking)\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model_eng(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    if (ranking[2] == 2):\n",
    "        return 0\n",
    "    elif (ranking[2] == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def analysis_vie(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = torch.tensor([tokenizer_vie.encode(text)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model_vie(encoded_input)\n",
    "        ranking = out.logits.softmax(dim=-1).tolist()[0]\n",
    "        top = np.argmax(ranking)\n",
    "    if (top == 2):\n",
    "        return 0\n",
    "    elif (top == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'comments_ede4_16t1kU.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments_ede4_16t1kU.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m comments:\n\u001b[0;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(comments)\n\u001b[0;32m      3\u001b[0m total_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'comments_ede4_16t1kU.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('comments_ede4_16t1kU.json', 'r') as comments:\n",
    "    data = json.load(comments)\n",
    "total_score = 0\n",
    "negatives = 0\n",
    "positives = 0\n",
    "neutrals = 0\n",
    "for i in data:\n",
    "    comment = next(iter(i.values()))\n",
    "    score = analysis(comment)\n",
    "    total_score += score\n",
    "    if (score == 1):\n",
    "        positives+=1\n",
    "    elif(score == 0):\n",
    "        neutrals+=1\n",
    "    else:\n",
    "        negatives+=1\n",
    "\n",
    "print(score)\n",
    "print(positives)\n",
    "print(neutrals)\n",
    "print(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vietnamese Model\n",
    "tokenizer_vie = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n",
    "config_vie = AutoConfig.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n",
    "model_vie = AutoModelForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "text = \"Tá»› thÃ­ch cáº­u\"\n",
    "print(analysis_vie(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  ÄÃºng cháº¥t há»a Long, biá»ƒu tÆ°á»£ng chá»¯ V thÃ nh 2 cÃ¡i rÃ¢u rá»“ng kÃ¬a. Äáº¹p\n",
      ">>  1\n",
      "\n",
      "-  xe Ä‘iá»‡n vf ráº¥t Ä‘áº¹p .mong vf ngÃ y cÃ ng phÃ¡t triá»ƒn hÃ¹ng máº¡nh\n",
      ">>  1\n",
      "\n",
      "-  Xe quÃ¡ Ä‘áº³ng cáº¥p,tá»± hÃ o Viá»‡t Nam lÃ m Ä‘Æ°á»£c xe nhÆ° váº­y\n",
      ">>  -1\n",
      "\n",
      "-  Mong chÃº sá»›m sáº¯m Ä‘Æ°á»£c má»™t con xe Vf7; chÃ¡u cÅ©ng tá»«ng tháº¥y chÃº lÃºc chÃº Ä‘i triá»ƒn lÃ£m Ã´ tÃ´ xanh Viá»‡t Nam vÃ  review máº¥y xe Ã´ tÃ´ á»Ÿ triá»ƒn lÃ£m rá»“i chÃº ah.\n",
      "ðŸ‡»ðŸ‡³\n",
      ">>  1\n",
      "\n",
      "-  Xe Ä‘áº¹p, cháº¥t lÆ°á»£ng hoÃ n thiá»‡n cÃ³ váº» Ä‘Ã£ khÃ¡ tá»‘t hÆ¡n nhá»¯ng xe tháº¿ há»‡ má»›i ra máº¯t Vf nhá»‰. Mong cho VF cÃ³ 1 nÄƒm thÃ nh cÃ´ng hÆ¡n ná»¯a trÃªn má»i thá»‹ trÆ°á»ng xe.\n",
      ">>  1\n",
      "\n",
      "-  Xe Ä‘áº¹p quÃ¡, Mong Vinfast ngÃ y cÃ ng phÃ¡t triá»ƒn, ra Ä‘Æ°á»£c máº«u sedan mui tráº§n ná»¯a thÃ¬ tuyá»‡t.\n",
      ">>  1\n",
      "\n",
      "-  KhÃ´ng mua thÃ¬ cÅ©ng Ä‘á»«ng buÃ´ng lá»i cay nghiá»‡t... vifat há» cÅ©ng Ä‘Ã£ nhiá»u cá»‘ gáº¯ng... ChÃºc nhÃ  sx nhiá»u thÃ nh cÃ´ng.\n",
      ">>  1\n",
      "\n",
      "-  CÃ³ 1 Con Hoáº£ long Ä‘á»™c báº£n Ä‘Æ°á»£c chá»§ xe Ä‘Ã³ng háº³n cÃ¡i biá»ƒn vÃ ng. ÄÃºng cháº¥t !\n",
      ">>  1\n",
      "\n",
      "-  ChÃº em nÃ y Ä‘Ã¡nh giÃ¡ Ã”tÃ´ ráº¥t chi tiáº¿t vÃ  cuá»‘n hÃºt ngÆ°á»i xem (nháº¥t lÃ  Ä‘Ã¡nh giÃ¡ con Civic)\n",
      ">>  1\n",
      "\n",
      "-  m cháº¡y quen cháº¿ Ä‘á»™ sport cá»§a e34 báº¯t Ä‘áº§u tháº¥y chÆ°a Ä‘á»§ Ä‘Ã´ rá»“i, thÃ¨m lÃªn máº¥y em 7 hoáº·c 8 láº¯m\n",
      ">>  1\n",
      "\n",
      "-  Xe qua dep\n",
      ">>  1\n",
      "\n",
      "-  Xe ráº¥t Ä‘áº¹p\n",
      ">>  1\n",
      "\n",
      "-  Ráº¥t Ä‘áº¹p vÃ  cháº¯c cháº¯n\n",
      ">>  1\n",
      "\n",
      "-  Con nÃ y Ä‘áº¹p.nhÃ¬n phÃª luÃ´n.7 chá»— thÃ¬ láº¡i tuyá»‡t vá»i.\n",
      ">>  1\n",
      "\n",
      "-  quÃ¡ dá»¯...   NhÃ¬n ngáº§u thiá»‡t...\n",
      ">>  1\n",
      "\n",
      "-  Äáº¹p hoÃ n háº£o\n",
      ">>  1\n",
      "\n",
      "-  Äáº¹p\n",
      ">>  1\n",
      "\n",
      "-  Äáº¹p tháº­t\n",
      ">>  1\n",
      "\n",
      "-  Tá»± nhiÃªn tháº¥y con Mazda CX8 6 gháº¿ cÃ¹i cá»§a mÃ¬nh thoáº£i mÃ¡i tháº­t ... CÅ©ng ngang giÃ¡ nhau.\n",
      ">>  1\n",
      "\n",
      "-  NhÃ¬n cháº¥t quÃ¡... \n",
      "ðŸ‡»ðŸ‡³\n",
      ">>  1\n",
      "\n",
      "-  Xe nÃ y Ä‘Ã¡nh sá»‘ thá»© tá»± á»Ÿ Ä‘Ã¢u váº­y bÃ¡c\n",
      ">>  -1\n",
      "\n",
      "-  QuÃ¡ Ä‘áº¹p\n",
      ">>  1\n",
      "\n",
      "-  Giá»›i thiá»‡u xe mÃ  chá»n cÃ¡i háº»m cháº­t chá»™i thÃ¬ lÃ m sao cÃ³ thá»ƒ quay toÃ n cáº£nh chiáº¿c xe\n",
      ">>  0\n",
      "\n",
      "-  Äáº¡p ga xe vá»t Ã¡c quÃ¡. Xe quÃ¡ máº¡nh quÃ¡ Ä‘áº¹p\n",
      ">>  1\n",
      "\n",
      "-  QuÃ¡ Ä‘áº³ng cáº¥p luÃ´n,Ä‘áº¹p khÃ´ng chÃª vÃ o Ä‘Ã¢u Ä‘Æ°á»£c\n",
      ">>  1\n",
      "\n",
      "-  phÃª tháº­t\n",
      ">>  1\n",
      "\n",
      "-  Nay mk cÅ©ng Ä‘Ã£ Ä‘c gáº·p báº£n há»a long ngÃ²ai Ä‘á»i rá»“i quÃ£ Ä‘áº¹p\n",
      ">>  1\n",
      "\n",
      "-  á»i rá»“i Ã´i xe vinfast Ä‘áº¹p khÃ´ng tÆ°á»Ÿng\n",
      ">>  1\n",
      "\n",
      "-  Nghe quÃ¡ nhiá»u cÃ¢u há»a long Ä‘á»™c báº£n!\n",
      ">>  1\n",
      "\n",
      "-  YÃªu vinfast\n",
      ">>  1\n",
      "\n",
      "-  Äáº¹p tháº­t sá»±\n",
      ">>  1\n",
      "\n",
      "-  Xe vinfast Ä‘áº¹p hÆ¡n cáº£ lan lÃ´ vo ná»¯a\n",
      ">>  1\n",
      "\n",
      "-  ToÃ n mÃ u Ä‘en mÃ  sao lÃ  há»a long nhá»‰? Ã” Long giá»‘ng hÆ¡n ^___^\n",
      ">>  -1\n",
      "\n",
      "-  Excuse my ignorance but can someone explain the significance/meaning behind the number of 68 for this version?  Thank you\n",
      ">>  1\n",
      "\n",
      "-  Láº¡i gioi háº¡n.thay quen quen.xong la kÃªt thuc luon.4ty gio 1.5ty k ai them\n",
      ">>  0\n",
      "\n",
      "-  vf7 ráº» xÃ­u ná»¯a thÃ¬ lÃ  chá»§ lá»±c doanh sá»‘ r`, giÃ¡ nhÃ­ch thÃªm tÃ½ ngta mua vf8\n",
      ">>  1\n",
      "\n",
      "-  Barbacena Mg Brasil\n",
      ">>  0\n",
      "\n",
      "-  2 tá»« tá»± hÃ o\n",
      ">>  0\n",
      "\n",
      "-  nÃ³i Ä‘i nÃ³i láº¡i chá»¯ há»a long Ä‘á»™c báº£n . nÃ³i 1 láº§n lÃ  Ä‘Æ°á»£c rá»“i\n",
      ">>  1\n",
      "\n",
      "-  Nghe báº£o má»›i ra 68 giÃ¢y Ä‘Ã£ bÃ¡n háº¿t, quÃ¡ Ä‘á»‰nh\n",
      ">>  1\n",
      "\n",
      "-  DÃ nh cho máº¥y Ã´ng giÃ . CÃ¡c báº¡n tráº» sáº½ ra báº£n BÄ‚NG LONG Äá»˜C Báº¢N sá»›m thÃ´i\n",
      ">>  1\n",
      "\n",
      "-  Vn tÃ´i yÃªu\n",
      ">>  1\n",
      "\n",
      "-  Ad lÃ m video vf7 mÃ o tráº¯ng ik\n",
      ">>  1\n",
      "\n",
      "-  há»a lÃ  lá»­a Ã \n",
      ">>  -1\n",
      "\n",
      "-  RiÃªng cÃ¡ nhÃ¢n minh thÃ¬ , mec khong bÃ¥ng\n",
      ">>  0\n",
      "\n",
      "-  chÃª má»—i cÃ¡i volang xáº¥u vÃ  thÃ´ thÃ´i cÃ²n Ä‘Ã¢u ko thá»ƒ chÃª Ä‘c Ä‘iá»u gÃ¬\n",
      ">>  -1\n",
      "\n",
      "-  Xe Ä‘áº¯t \n",
      " tháº­t\n",
      ">>  -1\n",
      "\n",
      "-  1:28 Hy vá»ng mÃ y nÃ y nÃ³ khÃ´ng bá»‹ bÃ´ng ra.\n",
      ">>  1\n",
      "\n",
      "-  Hello cÃ´ng nháº­n cÃ¡i diá»‡n cá»§a mÃ y áº¥y cÃ¡i Ä‘iá»ƒm dÃ¢n tá»™c cá»§a mÃ y nÃ³i quÃ¡ hay luÃ´n nÃ³i thiá»‡t lÃ  hay luÃ´n Ä‘Ãºng hay em Báº©u thÃ¬ nhÃ¢n tá»™c ruá»“i hoáº·c dÃ¬ nÃ³i chuyá»‡n quÃ¡ hay Ä‘Ãºng lÃ  cÃ¡i game thiÃªn tÃ i luÃ´n nÃ³i cÃ¡i gÃ¬ cÅ©ng hay ra Ä‘Ãºng lÃ  cÃ¡i game tá»• tiÃªn lÃ  hay thiá»‡t luÃ´n hay tháº¿ giá»›i khÃ´ng pháº£i lá»… mÃ \n",
      ">>  -1\n",
      "\n",
      "-  21/5/2024: Vinfast bá»‹ liÃªn bang Ä‘iá»u tra vá»¥ tai náº¡n 4 ngÆ°á»i cháº¿t á»Ÿ Pleasanton California\n",
      ">>  -1\n",
      "\n",
      "-  Mik tháº¥y ko Ä‘áº¹p\n",
      ">>  -1\n",
      "\n",
      "-  xe tÃ u, Ä‘áº¿n cÃ¡i tÃªn cÅ©ng dÃ¹ng tá»« hÃ¡n viá»‡t ná»¯a\n",
      ">>  1\n",
      "\n",
      "-  Äáº§u nhÃ¬n chÃ¡n\n",
      ">>  -1\n",
      "\n",
      "-  CÃ¡i tÃªn há»a Long  thÃ¬ cÃ¡i viá»n cá»§a cÃ¡i miá»‡ng nÃ³ pháº£i mÃ u Ä‘á» má»›i pháº£i chá»© nhá»‰, vá»›i láº¡i máº§u Ä‘á» vá»›i Ä‘en thÃ¬ nÃ³ sáº½ ná»•i vÃ  Ä‘áº¹p hÆ¡n ráº¥t nhiá»u\n",
      ">>  0\n",
      "\n",
      "-  Äáº¹p tháº­t\n",
      ">>  1\n",
      "\n",
      "total_score 29\n",
      "positives: 39\n",
      "neutrals: 6\n",
      "negatives: 10\n"
     ]
    }
   ],
   "source": [
    "#Open a Vietnamese comments\n",
    "with open(\"./comments/comments_CBMK6jHsR5Y.json\", \"r\", encoding='utf-8') as comments:\n",
    "    data_str = comments.read()\n",
    "    data = json.loads(data_str)\n",
    "#Total Score = negatives(-1) + neutrals(0) + positives(1)\n",
    "total_score = 0\n",
    "negatives = 0\n",
    "positives = 0\n",
    "neutrals = 0\n",
    "for i in data:\n",
    "    comment = next(iter(i.values()))\n",
    "    print(\"- \", comment)\n",
    "    score = analysis_vie(comment)\n",
    "    print(\">> \", score)\n",
    "    print(\"\")\n",
    "    if (score == 1):\n",
    "        positives+=1\n",
    "    elif(score == 0):\n",
    "        neutrals+=1\n",
    "    else:\n",
    "        negatives+=1\n",
    "\n",
    "\n",
    "print(\"total_score\", -1*negatives + positives)\n",
    "print(\"positives:\", positives)\n",
    "print(\"neutrals:\", neutrals)\n",
    "print(\"negatives:\", negatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
