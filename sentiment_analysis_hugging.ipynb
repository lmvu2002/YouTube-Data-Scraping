{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig, RobertaForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import json\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model_eng = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(MODEL)\n",
    "text = \"Hi!\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model_eng(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[2 1 0]\n",
      "1) positive 0.7172\n",
      "2) neutral 0.2652\n",
      "3) negative 0.0176\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(scores)\n",
    "print(ranking)\n",
    "ranking = ranking[::-1]\n",
    "print(ranking)\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model_eng(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    if (ranking[2] == 2):\n",
    "        return 0\n",
    "    elif (ranking[2] == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def analysis_vie(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = torch.tensor([tokenizer_vie.encode(text)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model_vie(encoded_input)\n",
    "        ranking = out.logits.softmax(dim=-1).tolist()[0]\n",
    "        top = np.argmax(ranking)\n",
    "    if (top == 2):\n",
    "        return 0\n",
    "    elif (top == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'comments_ede4_16t1kU.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments_ede4_16t1kU.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m comments:\n\u001b[0;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(comments)\n\u001b[0;32m      3\u001b[0m total_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'comments_ede4_16t1kU.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('comments_ede4_16t1kU.json', 'r') as comments:\n",
    "    data = json.load(comments)\n",
    "total_score = 0\n",
    "negatives = 0\n",
    "positives = 0\n",
    "neutrals = 0\n",
    "for i in data:\n",
    "    comment = next(iter(i.values()))\n",
    "    score = analysis(comment)\n",
    "    total_score += score\n",
    "    if (score == 1):\n",
    "        positives+=1\n",
    "    elif(score == 0):\n",
    "        neutrals+=1\n",
    "    else:\n",
    "        negatives+=1\n",
    "\n",
    "print(score)\n",
    "print(positives)\n",
    "print(neutrals)\n",
    "print(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vietnamese Model\n",
    "tokenizer_vie = AutoTokenizer.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n",
    "config_vie = AutoConfig.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n",
    "model_vie = AutoModelForSequenceClassification.from_pretrained(\"wonrax/phobert-base-vietnamese-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "text = \"T·ªõ th√≠ch c·∫≠u\"\n",
    "print(analysis_vie(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  ƒê√∫ng ch·∫•t h·ªèa Long, bi·ªÉu t∆∞·ª£ng ch·ªØ V th√†nh 2 c√°i r√¢u r·ªìng k√¨a. ƒê·∫πp\n",
      ">>  1\n",
      "\n",
      "-  xe ƒëi·ªán vf r·∫•t ƒë·∫πp .mong vf ng√†y c√†ng ph√°t tri·ªÉn h√πng m·∫°nh\n",
      ">>  1\n",
      "\n",
      "-  Xe qu√° ƒë·∫≥ng c·∫•p,t·ª± h√†o Vi·ªát Nam l√†m ƒë∆∞·ª£c xe nh∆∞ v·∫≠y\n",
      ">>  -1\n",
      "\n",
      "-  Mong ch√∫ s·ªõm s·∫Øm ƒë∆∞·ª£c m·ªôt con xe Vf7; ch√°u c≈©ng t·ª´ng th·∫•y ch√∫ l√∫c ch√∫ ƒëi tri·ªÉn l√£m √¥ t√¥ xanh Vi·ªát Nam v√† review m·∫•y xe √¥ t√¥ ·ªü tri·ªÉn l√£m r·ªìi ch√∫ ah.\n",
      "üáªüá≥\n",
      ">>  1\n",
      "\n",
      "-  Xe ƒë·∫πp, ch·∫•t l∆∞·ª£ng ho√†n thi·ªán c√≥ v·∫ª ƒë√£ kh√° t·ªët h∆°n nh·ªØng xe th·∫ø h·ªá m·ªõi ra m·∫Øt Vf nh·ªâ. Mong cho VF c√≥ 1 nƒÉm th√†nh c√¥ng h∆°n n·ªØa tr√™n m·ªçi th·ªã tr∆∞·ªùng xe.\n",
      ">>  1\n",
      "\n",
      "-  Xe ƒë·∫πp qu√°, Mong Vinfast ng√†y c√†ng ph√°t tri·ªÉn, ra ƒë∆∞·ª£c m·∫´u sedan mui tr·∫ßn n·ªØa th√¨ tuy·ªát.\n",
      ">>  1\n",
      "\n",
      "-  Kh√¥ng mua th√¨ c≈©ng ƒë·ª´ng bu√¥ng l·ªùi cay nghi·ªát... vifat h·ªç c≈©ng ƒë√£ nhi·ªÅu c·ªë g·∫Øng... Ch√∫c nh√† sx nhi·ªÅu th√†nh c√¥ng.\n",
      ">>  1\n",
      "\n",
      "-  C√≥ 1 Con Ho·∫£ long ƒë·ªôc b·∫£n ƒë∆∞·ª£c ch·ªß xe ƒë√≥ng h·∫≥n c√°i bi·ªÉn v√†ng. ƒê√∫ng ch·∫•t !\n",
      ">>  1\n",
      "\n",
      "-  Ch√∫ em n√†y ƒë√°nh gi√° √ît√¥ r·∫•t chi ti·∫øt v√† cu·ªën h√∫t ng∆∞·ªùi xem (nh·∫•t l√† ƒë√°nh gi√° con Civic)\n",
      ">>  1\n",
      "\n",
      "-  m ch·∫°y quen ch·∫ø ƒë·ªô sport c·ªßa e34 b·∫Øt ƒë·∫ßu th·∫•y ch∆∞a ƒë·ªß ƒë√¥ r·ªìi, th√®m l√™n m·∫•y em 7 ho·∫∑c 8 l·∫Øm\n",
      ">>  1\n",
      "\n",
      "-  Xe qua dep\n",
      ">>  1\n",
      "\n",
      "-  Xe r·∫•t ƒë·∫πp\n",
      ">>  1\n",
      "\n",
      "-  R·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn\n",
      ">>  1\n",
      "\n",
      "-  Con n√†y ƒë·∫πp.nh√¨n ph√™ lu√¥n.7 ch·ªó th√¨ l·∫°i tuy·ªát v·ªùi.\n",
      ">>  1\n",
      "\n",
      "-  qu√° d·ªØ...   Nh√¨n ng·∫ßu thi·ªát...\n",
      ">>  1\n",
      "\n",
      "-  ƒê·∫πp ho√†n h·∫£o\n",
      ">>  1\n",
      "\n",
      "-  ƒê·∫πp\n",
      ">>  1\n",
      "\n",
      "-  ƒê·∫πp th·∫≠t\n",
      ">>  1\n",
      "\n",
      "-  T·ª± nhi√™n th·∫•y con Mazda CX8 6 gh·∫ø c√πi c·ªßa m√¨nh tho·∫£i m√°i th·∫≠t ... C≈©ng ngang gi√° nhau.\n",
      ">>  1\n",
      "\n",
      "-  Nh√¨n ch·∫•t qu√°... \n",
      "üáªüá≥\n",
      ">>  1\n",
      "\n",
      "-  Xe n√†y ƒë√°nh s·ªë th·ª© t·ª± ·ªü ƒë√¢u v·∫≠y b√°c\n",
      ">>  -1\n",
      "\n",
      "-  Qu√° ƒë·∫πp\n",
      ">>  1\n",
      "\n",
      "-  Gi·ªõi thi·ªáu xe m√† ch·ªçn c√°i h·∫ªm ch·∫≠t ch·ªôi th√¨ l√†m sao c√≥ th·ªÉ quay to√†n c·∫£nh chi·∫øc xe\n",
      ">>  0\n",
      "\n",
      "-  ƒê·∫°p ga xe v·ªçt √°c qu√°. Xe qu√° m·∫°nh qu√° ƒë·∫πp\n",
      ">>  1\n",
      "\n",
      "-  Qu√° ƒë·∫≥ng c·∫•p lu√¥n,ƒë·∫πp kh√¥ng ch√™ v√†o ƒë√¢u ƒë∆∞·ª£c\n",
      ">>  1\n",
      "\n",
      "-  ph√™ th·∫≠t\n",
      ">>  1\n",
      "\n",
      "-  Nay mk c≈©ng ƒë√£ ƒëc g·∫∑p b·∫£n h·ªèa long ng√≤ai ƒë·ªùi r·ªìi qu√£ ƒë·∫πp\n",
      ">>  1\n",
      "\n",
      "-  ·ªêi r·ªìi √¥i xe vinfast ƒë·∫πp kh√¥ng t∆∞·ªüng\n",
      ">>  1\n",
      "\n",
      "-  Nghe qu√° nhi·ªÅu c√¢u h·ªèa long ƒë·ªôc b·∫£n!\n",
      ">>  1\n",
      "\n",
      "-  Y√™u vinfast\n",
      ">>  1\n",
      "\n",
      "-  ƒê·∫πp th·∫≠t s·ª±\n",
      ">>  1\n",
      "\n",
      "-  Xe vinfast ƒë·∫πp h∆°n c·∫£ lan l√¥ vo n·ªØa\n",
      ">>  1\n",
      "\n",
      "-  To√†n m√†u ƒëen m√† sao l√† h·ªèa long nh·ªâ? √î Long gi·ªëng h∆°n ^___^\n",
      ">>  -1\n",
      "\n",
      "-  Excuse my ignorance but can someone explain the significance/meaning behind the number of 68 for this version?  Thank you\n",
      ">>  1\n",
      "\n",
      "-  L·∫°i gioi h·∫°n.thay quen quen.xong la k√™t thuc luon.4ty gio 1.5ty k ai them\n",
      ">>  0\n",
      "\n",
      "-  vf7 r·∫ª x√≠u n·ªØa th√¨ l√† ch·ªß l·ª±c doanh s·ªë r`, gi√° nh√≠ch th√™m t√Ω ngta mua vf8\n",
      ">>  1\n",
      "\n",
      "-  Barbacena Mg Brasil\n",
      ">>  0\n",
      "\n",
      "-  2 t·ª´ t·ª± h√†o\n",
      ">>  0\n",
      "\n",
      "-  n√≥i ƒëi n√≥i l·∫°i ch·ªØ h·ªèa long ƒë·ªôc b·∫£n . n√≥i 1 l·∫ßn l√† ƒë∆∞·ª£c r·ªìi\n",
      ">>  1\n",
      "\n",
      "-  Nghe b·∫£o m·ªõi ra 68 gi√¢y ƒë√£ b√°n h·∫øt, qu√° ƒë·ªânh\n",
      ">>  1\n",
      "\n",
      "-  D√†nh cho m·∫•y √¥ng gi√†. C√°c b·∫°n tr·∫ª s·∫Ω ra b·∫£n BƒÇNG LONG ƒê·ªòC B·∫¢N s·ªõm th√¥i\n",
      ">>  1\n",
      "\n",
      "-  Vn t√¥i y√™u\n",
      ">>  1\n",
      "\n",
      "-  Ad l√†m video vf7 m√†o tr·∫Øng ik\n",
      ">>  1\n",
      "\n",
      "-  h·ªèa l√† l·ª≠a √†\n",
      ">>  -1\n",
      "\n",
      "-  Ri√™ng c√° nh√¢n minh th√¨ , mec khong b√•ng\n",
      ">>  0\n",
      "\n",
      "-  ch√™ m·ªói c√°i volang x·∫•u v√† th√¥ th√¥i c√≤n ƒë√¢u ko th·ªÉ ch√™ ƒëc ƒëi·ªÅu g√¨\n",
      ">>  -1\n",
      "\n",
      "-  Xe ƒë·∫Øt \n",
      " th·∫≠t\n",
      ">>  -1\n",
      "\n",
      "-  1:28 Hy v·ªçng m√†y n√†y n√≥ kh√¥ng b·ªã b√¥ng ra.\n",
      ">>  1\n",
      "\n",
      "-  Hello c√¥ng nh·∫≠n c√°i di·ªán c·ªßa m√†y ·∫•y c√°i ƒëi·ªÉm d√¢n t·ªôc c·ªßa m√†y n√≥i qu√° hay lu√¥n n√≥i thi·ªát l√† hay lu√¥n ƒë√∫ng hay em B·∫©u th√¨ nh√¢n t·ªôc ru·ªìi ho·∫∑c d√¨ n√≥i chuy·ªán qu√° hay ƒë√∫ng l√† c√°i game thi√™n t√†i lu√¥n n√≥i c√°i g√¨ c≈©ng hay ra ƒë√∫ng l√† c√°i game t·ªï ti√™n l√† hay thi·ªát lu√¥n hay th·∫ø gi·ªõi kh√¥ng ph·∫£i l·ªÖ m√†\n",
      ">>  -1\n",
      "\n",
      "-  21/5/2024: Vinfast b·ªã li√™n bang ƒëi·ªÅu tra v·ª• tai n·∫°n 4 ng∆∞·ªùi ch·∫øt ·ªü Pleasanton California\n",
      ">>  -1\n",
      "\n",
      "-  Mik th·∫•y ko ƒë·∫πp\n",
      ">>  -1\n",
      "\n",
      "-  xe t√†u, ƒë·∫øn c√°i t√™n c≈©ng d√πng t·ª´ h√°n vi·ªát n·ªØa\n",
      ">>  1\n",
      "\n",
      "-  ƒê·∫ßu nh√¨n ch√°n\n",
      ">>  -1\n",
      "\n",
      "-  C√°i t√™n h·ªèa Long  th√¨ c√°i vi·ªÅn c·ªßa c√°i mi·ªáng n√≥ ph·∫£i m√†u ƒë·ªè m·ªõi ph·∫£i ch·ª© nh·ªâ, v·ªõi l·∫°i m·∫ßu ƒë·ªè v·ªõi ƒëen th√¨ n√≥ s·∫Ω n·ªïi v√† ƒë·∫πp h∆°n r·∫•t nhi·ªÅu\n",
      ">>  0\n",
      "\n",
      "-  ƒê·∫πp th·∫≠t\n",
      ">>  1\n",
      "\n",
      "total_score 29\n",
      "positives: 39\n",
      "neutrals: 6\n",
      "negatives: 10\n"
     ]
    }
   ],
   "source": [
    "#Open a Vietnamese comments\n",
    "with open(\"./comments/comments_CBMK6jHsR5Y.json\", \"r\", encoding='utf-8') as comments:\n",
    "    data_str = comments.read()\n",
    "    data = json.loads(data_str)\n",
    "#Total Score = negatives(-1) + neutrals(0) + positives(1)\n",
    "total_score = 0\n",
    "negatives = 0\n",
    "positives = 0\n",
    "neutrals = 0\n",
    "for i in data:\n",
    "    comment = next(iter(i.values()))\n",
    "    print(\"- \", comment)\n",
    "    score = analysis_vie(comment)\n",
    "    print(\">> \", score)\n",
    "    print(\"\")\n",
    "    if (score == 1):\n",
    "        positives+=1\n",
    "    elif(score == 0):\n",
    "        neutrals+=1\n",
    "    else:\n",
    "        negatives+=1\n",
    "\n",
    "\n",
    "print(\"total_score\", -1*negatives + positives)\n",
    "print(\"positives:\", positives)\n",
    "print(\"neutrals:\", neutrals)\n",
    "print(\"negatives:\", negatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
